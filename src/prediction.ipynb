{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/pbc/Pycharm Projects/myNewPro/pre-model/longformer/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import config_iProL_test as config\n",
    "from dataset import RegulonDataset\n",
    "from dataset import get_excel, get_complete_data, get_split_dataset\n",
    "from dataset import get_datasets, get_cv_dataloader_list, feature_exaction\n",
    "from feature_extraction import Kmer\n",
    "from module import Longformer_base_Net, Longformer_base_lstm_Net, Bert_base_lstm_Net\n",
    "from tools import get_scoring_result, drawLoss, check_result_dir, get_config_info, save_score\n",
    "from tools_fit import model_fit\n",
    "\n",
    "\n",
    "\n",
    "model = Longformer_base_lstm_Net(config.model_name, config.device,\n",
    "                                 config.add_special_tokens,\n",
    "                                 bidirectional=config.bidirectional,\n",
    "                                 num_layers=config.num_layers)\n",
    "model.load_state_dict(torch.load(\"../model/model_137.pkl\"))\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "model.to(config.device)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBC[test] --- kmer = 2\n",
      "train len: 6764 test len: 395\n"
     ]
    }
   ],
   "source": [
    "sheet = get_excel(version='', sheet_name='dataset')\n",
    "complete_data = get_complete_data(sheet)\n",
    "dataset_train, _, _ = get_datasets(complete_data)\n",
    "\n",
    "sheet = get_excel(version='11.1', sheet_name='test_0.85')\n",
    "complete_data = get_complete_data(sheet)\n",
    "dataset_test, _, _ = get_datasets(complete_data)\n",
    "train_loader, test_loader = feature_exaction(config, [dataset_train, dataset_test], \"Pro\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total=395, TP=367, TN=0, FP=0, FN=28; precision=1.000, recall=0.929, Sn=0.929, Sp=nan\n",
      "accuracy: (test=0.929) matthews_corrcoef: (test=0.000) f1: (test=0.963) \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss_test = 0\n",
    "y_test = []\n",
    "y_prob = []\n",
    "with torch.no_grad():\n",
    "    for idx_test, (X, y) in enumerate(test_loader, 1):\n",
    "        try:\n",
    "            X = X.to(config.device)\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            pass\n",
    "        y = y.float().to(config.device)\n",
    "        # print(X.shape, y.shape)\n",
    "        y_hat = model(X)\n",
    "        loss = criterion(y_hat, y)\n",
    "        total_loss_test += loss.item()\n",
    "\n",
    "        y_test.extend(y.to('cpu').tolist())\n",
    "        y_prob.extend(y_hat.to('cpu').tolist())\n",
    "        # if idx_test % 20 == 0:\n",
    "        #     print(f'epoch {epoch} [{idx_test}/{len(train_loader)}] batch_loss = {loss.item()}')\n",
    "    y_pred = [1 if item >= 0.5 else 0 for item in y_prob]\n",
    "\n",
    "\n",
    "    scoring = ['accuracy', 'matthews_corrcoef', 'f1']\n",
    "    process_msg, test_score_dict = get_scoring_result(scoring, y_test, y_pred, y_prob)\n",
    "    print(process_msg)\n",
    "    test_loss_epoch = total_loss_test / idx_test * 1.0\n",
    "    # return test_loss_epoch, test_score_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import os\n",
    "file = \"./iProL_re.txt\"\n",
    "with open(file,'w') as f:\n",
    "    # if not os.path.exists(file):\n",
    "    #     os.path.\n",
    "    f.writelines([str(p)+\"\\n\" for p in y_pred])\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
